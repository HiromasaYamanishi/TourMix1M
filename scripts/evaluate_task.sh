python eval.py evaluate_qa_metric  --checkpoint llava-v1.5-13b-jalan-review-lora-v16_6epoch --mode pvqa --model_names ['llavatour']
python eval.py evaluate_qa_metric  --checkpoint llava-v1.5-13b-jalan-review-lora-v15_5epoch --mode pvqa --model_names ['llavatour']
python eval.py evaluate_qa_metric  --checkpoint llava-v1.5-13b-jalan-review-lora-v14_4epoch --mode pvqa --model_names ['llavatour']
python eval.py evaluate_qa_metric  --mode pvqa --model_names ['llava']
python eval.py evaluate_qa_metric  --mode pvqa --model_names ['gpt4v']
python eval.py evaluate_qa_metric  --checkpoint llava-v1.5-13b-jalan-review-lora-v16_6epoch --mode qa --model_names ['llavatour']
python eval.py evaluate_qa_metric  --checkpoint llava-v1.5-13b-jalan-review-lora-v15_5epoch --mode qa --model_names ['llavatour']
python eval.py evaluate_qa_metric  --checkpoint llava-v1.5-13b-jalan-review-lora-v14_4epoch --mode qa --model_names ['llavatour']
python eval.py evaluate_qa_metric  --mode qa --model_names ['llava']
python eval.py evaluate_qa_metric  --mode qa --model_names ['gpt3']
